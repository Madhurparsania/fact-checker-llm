{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1fae62-21e1-4e36-9d66-215aa9e59e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in d:\\anaconda\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: transformers in d:\\anaconda\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: sentence-transformers in d:\\anaconda\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: faiss-cpu in d:\\anaconda\\lib\\site-packages (1.13.0)\n",
      "Requirement already satisfied: openai in d:\\anaconda\\lib\\site-packages (2.8.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: packaging<25,>=20 in d:\\anaconda\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in d:\\anaconda\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in d:\\anaconda\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in d:\\anaconda\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in d:\\anaconda\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in d:\\anaconda\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in d:\\anaconda\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in d:\\anaconda\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in d:\\anaconda\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in d:\\anaconda\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in d:\\anaconda\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\anaconda\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\anaconda\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in d:\\anaconda\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\anaconda\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\anaconda\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in d:\\anaconda\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\anaconda\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\anaconda\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit transformers sentence-transformers faiss-cpu openai numpy pandas torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad98ce1-c857-4846-869f-71193de35938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e96bf07d-0f40-44c6-afbf-78cc2beafb25",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'facts.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m facts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(facts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m facts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'facts.csv'"
     ]
    }
   ],
   "source": [
    "facts = pd.read_csv('facts.csv')['fact'].tolist()\n",
    "print(f\"Loaded {len(facts)} facts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fe0b4e-81d1-47d4-b57f-b5bf13bf30d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Assignment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6316e821-1b5d-4f24-813a-afbafcfcc380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f312d81-13af-44af-96fa-9eb67dc4023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'assignment.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e14011-9289-481d-842e-24bc9a3f388b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 20, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m facts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfact\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(facts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m facts.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m         nrows\n\u001b[0;32m   1925\u001b[0m     )\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 20, saw 2\n"
     ]
    }
   ],
   "source": [
    "facts = pd.read_csv('facts.csv')['fact'].tolist()\n",
    "print(f\"Loaded {len(facts)} facts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd5a0f02-0152-45cf-b15a-c619f26c77d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts.csv fixed and created at: C:\\Users\\Administrator\\Assignment\n"
     ]
    }
   ],
   "source": [
    "facts_list = [\n",
    "    \"India’s GDP grew by 7.2% in 2024.\",\n",
    "    \"The Indian government has announced free electricity to all farmers starting July 2025.\",\n",
    "    \"Aadhaar cards are required for all government schemes.\",\n",
    "    \"COVID-19 vaccinations were made free for adults in India in 2021.\",\n",
    "    \"Solar power adoption among Indian farmers rose by 10% since 2024.\",\n",
    "    \"GST rate changes were announced in December 2025.\",\n",
    "    \"Minimum support price for wheat was raised in 2025.\",\n",
    "    \"Ayushman Bharat provides free healthcare to families below poverty line.\",\n",
    "    \"Jan Dhan Yojana has helped open over 450 million bank accounts.\",\n",
    "    \"Interest rates on student loans were reduced in September 2025.\",\n",
    "    # ... You can add up to 100 facts here, one per string, NO commas except inside quotes ...\n",
    "]\n",
    "import pandas as pd\n",
    "import os\n",
    "df = pd.DataFrame({'fact': facts_list})\n",
    "df.to_csv('facts.csv', index=False)\n",
    "print(\"facts.csv fixed and created at:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "114de627-b1b9-42d8-906f-bb4e4a1593a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 facts.\n"
     ]
    }
   ],
   "source": [
    "facts = pd.read_csv('facts.csv')['fact'].tolist()\n",
    "print(f\"Loaded {len(facts)} facts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58105de8-9d1d-4ebd-b4c6-f7aeec590c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts.csv created with 103 facts.\n"
     ]
    }
   ],
   "source": [
    "facts_list = [\n",
    "    \"The Indian government has announced free electricity to all farmers starting July 2025.\",\n",
    "    \"India’s GDP grew by 7.2% in 2024.\",\n",
    "    \"The central bank raised interest rates in June 2025.\",\n",
    "    \"Aadhaar cards are required for all government schemes.\",\n",
    "    \"COVID-19 vaccinations were made free for adults in India in 2021.\",\n",
    "    \"Electricity subsidies in Karnataka were increased in 2025.\",\n",
    "    \"Solar power adoption among Indian farmers rose by 10% since 2024.\",\n",
    "    \"Minimum support price for wheat was raised in 2025.\",\n",
    "    \"GST rate changes were announced in December 2025.\",\n",
    "    \"Jal Jeevan Mission targets water access to all rural households by 2026.\",\n",
    "    \"India’s literacy rate crossed 80% in 2025.\",\n",
    "    \"Ayushman Bharat provides free healthcare to families below poverty line.\",\n",
    "    \"Jan Dhan Yojana has helped open over 450 million bank accounts.\",\n",
    "    \"Mobile data usage in India increased by 40% in 2025.\",\n",
    "    \"The government launched the Digital India initiative in 2015.\",\n",
    "    \"Interest rates on student loans were reduced in September 2025.\",\n",
    "    \"Wind energy accounted for 8% of India’s electricity generation in 2024.\",\n",
    "    \"Renewable energy capacity in India reached 168 GW in 2025.\",\n",
    "    \"The PM-KISAN scheme provides ₹6,000 annually to farmers.\",\n",
    "    \"Inflation in India averaged 4.3% during 2025.\",\n",
    "    \"The unemployment rate fell to 5.6% in March 2025.\",\n",
    "    \"Agricultural exports from India hit $53 billion in 2024.\",\n",
    "    \"Direct Benefit Transfer reduced subsidy leakages by 30%.\",\n",
    "    \"NITI Aayog released the latest SDG Index in August 2025.\",\n",
    "    \"Self-help groups increased by 18% since 2023.\",\n",
    "    \"Government started ration card portability in 2024.\",\n",
    "    \"Rainfall in Kerala was above normal in June 2025.\",\n",
    "    \"India produces the most pulses worldwide.\",\n",
    "    \"Female labor force participation rose to 24% in 2025.\",\n",
    "    \"Swachh Bharat Mission improved rural sanitation coverage to 98%.\",\n",
    "    \"The latest Census was conducted in 2021.\",\n",
    "    \"The number of startups in India crossed 100,000 in 2025.\",\n",
    "    \"ISRO launched Aditya-L1 solar mission in 2023.\",\n",
    "    \"PM Narendra Modi was re-elected in 2024.\",\n",
    "    \"Ujjwala scheme provided LPG connections to over 80 million households.\",\n",
    "    \"India’s road network became the second largest globally in 2025.\",\n",
    "    \"Elections for Lok Sabha were held in May 2024.\",\n",
    "    \"E-commerce spending in India topped $120 billion in 2025.\",\n",
    "    \"National Education Policy was changed in 2020.\",\n",
    "    \"UPI transactions surpassed 12 billion monthly in 2025.\",\n",
    "    \"A vaccine for dengue was approved in 2024.\",\n",
    "    \"Metro rail expanded to 20 major Indian cities as of 2025.\",\n",
    "    \"Digital payment frauds reported fell by 18% in 2025.\",\n",
    "    \"India is the world’s largest milk producer.\",\n",
    "    \"The new criminal procedure code was passed in 2024.\",\n",
    "    \"Covid-19 lockdown began in India on March 25, 2020.\",\n",
    "    \"India’s population exceeded 1.44 billion in 2025.\",\n",
    "    \"The Vande Bharat Express launched on five new routes in 2025.\",\n",
    "    \"The central government adopted the Agnipath military recruitment scheme in 2022.\",\n",
    "    \"The country’s median age reached 29 years in 2025.\",\n",
    "    \"Female literacy in Kerala reached 99% in 2025.\",\n",
    "    \"Online education doubled in enrollment between 2020 and 2025.\",\n",
    "    \"India’s tallest bridge is the Chenab Rail Bridge in J&K.\",\n",
    "    \"The consumer price index rose by 5.2% in October 2025.\",\n",
    "    \"India banned single-use plastics in July 2022.\",\n",
    "    \"NIPUN Bharat Mission aims for foundational literacy by 2026.\",\n",
    "    \"The Statue of Unity is the world’s tallest statue.\",\n",
    "    \"New tax slabs were announced in February 2025.\",\n",
    "    \"India is the third largest startup hub in the world.\",\n",
    "    \"Farm loan waivers were issued in three states in 2024.\",\n",
    "    \"Tenth Pay Commission was implemented in July 2025.\",\n",
    "    \"The PM Suraksha Bima Yojana offers insurance of ₹2 lakh.\",\n",
    "    \"Government raised tiger conservation funding in 2025.\",\n",
    "    \"Solar rooftop installations crossed 2 million in 2025.\",\n",
    "    \"Regional rapid transit system started between Delhi and Meerut in 2025.\",\n",
    "    \"India allowed 100% FDI in telecom in 2024.\",\n",
    "    \"AICTE approved new engineering syllabi in September 2025.\",\n",
    "    \"The total forest cover of India increased by 4% since 2023.\",\n",
    "    \"Jan Aushadhi stores now offer 1,500 generic medicines.\",\n",
    "    \"Inflation-adjusted pensions for veterans were introduced in 2025.\",\n",
    "    \"India imported 18 million tons of crude oil from Russia in 2024.\",\n",
    "    \"Food processing sector employment grew by 15% in 2025.\",\n",
    "    \"India’s average life expectancy reached 71 years in 2025.\",\n",
    "    \"The pharma sector exported $25 billion worth of drugs in 2024.\",\n",
    "    \"The Golden Quadrilateral highways were built by 2005.\",\n",
    "    \"NEP 2020 recommends mother tongue in primary schools.\",\n",
    "    \"Government funding for AI research reached ₹2000 crore in 2025.\",\n",
    "    \"Pradhan Mantri Gram Sadak Yojana built 700,000 km of roads.\",\n",
    "    \"Farmer suicides dropped by 12% in 2024.\",\n",
    "    \"India became the world’s second largest rice exporter in 2024.\",\n",
    "    \"Maternity leave in government jobs increased to 26 weeks.\",\n",
    "    \"40 crore doses of COVID-19 vaccines were administered by July 2021.\",\n",
    "    \"The largest solar park is Bhadla Solar Park in Rajasthan.\",\n",
    "    \"The Nirbhaya Fund was increased in 2025.\",\n",
    "    \"Health insurance coverage crossed 50% for Indian families in 2025.\",\n",
    "    \"Indian Railways electrified 80% of routes by November 2025.\",\n",
    "    \"The GST Council raised compensation cess on luxury goods in 2025.\",\n",
    "    \"National Digital Health Mission launched in 2021.\",\n",
    "    \"The percentage of children under five with stunted growth fell to 23% in 2025.\",\n",
    "    \"MGNREGA provided 3 billion workdays in 2025.\",\n",
    "    \"The RBI digital rupee pilot began in Mumbai in 2024.\",\n",
    "    \"MG Motor India opened its electric vehicle plant in Gujarat in 2025.\",\n",
    "    \"Jeevan Pramaan enabled digital life certificates for pensioners.\",\n",
    "    \"The minimum wage for industrial workers increased by ₹500 in 2025.\",\n",
    "    \"The Aatmanirbhar Bharat initiative started in 2020.\",\n",
    "    \"Government built 10 million affordable homes under PMAY by 2025.\",\n",
    "    \"ISRO successfully launched Chandrayaan-3 in 2023.\",\n",
    "    \"The Defence budget for India reached ₹6 lakh crore in 2025.\",\n",
    "    \"Festivals like Diwali and Holi are celebrated nationwide.\",\n",
    "    \"India’s literacy rate among urban youth reached 94% in 2025.\",\n",
    "    \"The latest National Family Health Survey was released in 2025.\",\n",
    "    \"All rural households to have piped water by 2026.\",\n",
    "    \"The BharatNet project connected 600,000 villages with broadband in 2025.\"\n",
    "]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'fact': facts_list})\n",
    "df.to_csv('facts.csv', index=False)\n",
    "print(\"facts.csv created with\", len(facts_list), \"facts.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "661a5801-f24e-4f5c-8c8e-6f39f52a9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts.csv created with 10 facts.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'fact': facts_list})\n",
    "df.to_csv('facts.csv', index=False)\n",
    "print(\"facts.csv created with\", len(facts_list), \"facts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff419adf-9446-4570-a48c-66840eefd646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facts.csv created with 10 facts.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'fact': facts_list})\n",
    "df.to_csv('facts.csv', index=False)\n",
    "print(\"facts.csv created with\", len(facts_list), \"facts.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2740502f-cc02-47bd-bed5-403174a3c171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ecac00298a4bd38bfd2e0d1fa8dc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a98c5e9b374cc385f014c875064bb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95e7b03808842ae971a84b2f26b2ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f35411f8f7b40f4a48dd8676ae28676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77850176707b4f37b9c361c02c9b3a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e559a3ef6ef4f678aa92b4d6d1e533e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fed3160928040e6b863b52d11ab7f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f4fe0d4a0348ba89a24ceec7088704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36aa282c8d4498cb6a65a299a5455eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd783341fa040c096c9e3c5b4ce318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a17d77d3bf4912944e9b8af206b636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83978a7e5ab840aabd559efe313da745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generated and saved as embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "facts = pd.read_csv('facts.csv')['fact'].tolist()\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(facts, show_progress_bar=True)\n",
    "np.save('embeddings.npy', embeddings)\n",
    "print(\"Embeddings generated and saved as embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e55cac-fde3-407c-b611-dc654f916c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index built.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "def build_faiss(embeddings):\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "embeddings = np.load('embeddings.npy')\n",
    "index = build_faiss(embeddings)\n",
    "print(\"FAISS index built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a6a3b52-6137-446f-80d8-0386d21de96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def extract_claim(text):\n",
    "    ner = pipeline(\"ner\", grouped_entities=True, model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "    entities = ner(text)\n",
    "    if entities:\n",
    "        claim = sorted(entities, key=lambda x: len(x['word']), reverse=True)[0]['word']\n",
    "    else:\n",
    "        claim = text\n",
    "    return claim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b805a5-ab63-4b31-94b4-afa260e53400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_similar_facts(index, query_emb, facts, top_k=3, return_scores=False):\n",
    "    D, I = index.search(query_emb, top_k)\n",
    "    results = [facts[i] for i in I[0]]\n",
    "    scores = [1 / (1 + D[0][j]) for j in range(top_k)]\n",
    "    if return_scores:\n",
    "        return results, scores\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ad85e6-ee56-47f0-88b3-32647af3cebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15e5e40f25a43cfa5e8ab0c69385b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d7a9b9757a4c33bfb85868608fe873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794900f907b144eeb5c8208d503688d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e73f8f3bb824632808a1ed777a552e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "D:\\Anaconda\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:186: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted claim: Indian\n",
      "\n",
      "Most Similar Facts:\n",
      "1. India is the world’s largest milk producer.  (Score: 0.44)\n",
      "2. India produces the most pulses worldwide.  (Score: 0.43)\n",
      "3. India’s literacy rate among urban youth reached 94% in 2025.  (Score: 0.43)\n",
      "\n",
      "Confidence Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "statement = \"The Indian government has announced free electricity to all farmers starting July 2025.\"\n",
    "\n",
    "claim = extract_claim(statement)\n",
    "print(\"Extracted claim:\", claim)\n",
    "\n",
    "query_emb = model.encode([claim])\n",
    "facts_found, scores = retrieve_similar_facts(index, query_emb, facts, top_k=3, return_scores=True)\n",
    "confidence = max(scores)\n",
    "\n",
    "print(\"\\nMost Similar Facts:\")\n",
    "for i, (fact, score) in enumerate(zip(facts_found, scores)):\n",
    "    print(f\"{i+1}. {fact}  (Score: {score:.2f})\")\n",
    "print(f\"\\nConfidence Score: {confidence:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cea8798-897f-448e-a9ce-ede0a77b59df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM Verdict & Reasoning:\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "def get_verdict_local(claim, retrieved_facts):\n",
    "    local_llm = pipeline('text2text-generation', model='google/flan-t5-base', max_length=200)\n",
    "    prompt = (\n",
    "        f\"Claim: {claim}\\n\"\n",
    "        f\"Relevant facts:\\n\" + \"\\n\".join(f\"- {fact}\" for fact in retrieved_facts) +\n",
    "        \"\\nIs the claim True, False, or Unverifiable? State the verdict and explain.\"\n",
    "    )\n",
    "    response = local_llm(prompt)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "verdict = get_verdict_local(claim, facts_found)\n",
    "print(\"\\nLLM Verdict & Reasoning:\\n\", verdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3d040d3-3928-4c47-9c94-1717680d06d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hf_xet in d:\\anaconda\\lib\\site-packages (1.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff4c19-57cc-46ca-af6c-fafe8e109205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
